{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from datascience import *\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy import stats \n",
    "from scipy.integrate import simps\n",
    "import subprocess\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "\n",
    "read_data = Table.read_table(\"Thagomizer_Runs/icos-cd4.csv\")\n",
    "chrom = \"chr1\"\n",
    "start = read_data.column(0).item(0)\n",
    "stop = read_data.column(0).item(read_data.num_rows - 1)\n",
    "columns = read_data.num_columns\n",
    "\n",
    "def MA_normalization(read_data):\n",
    "    M = np.log(read_data.column(1) + .999999) - np.log(read_data.column(2) + .999999)\n",
    "    A = (np.log(read_data.column(1) + .999999) + np.log(read_data.column(2) + .999999))\n",
    "    slope, intercept, r_value, p_value, std_err =  stats.linregress(A,M)\n",
    "    adjusted_M = M - ((slope*A)+intercept)\n",
    "    return Table().with_columns(\"Adjusted M\", adjusted_M, \"A\", A)\n",
    "\n",
    "def ranges(nums):\n",
    "    nums = sorted(set(nums))\n",
    "    gaps = [[s, e] for s, e in zip(nums, nums[1:]) if s+1 < e]\n",
    "    edges = iter(nums[:1] + sum(gaps, []) + nums[-1:])\n",
    "    summ = list(zip(edges, edges))\n",
    "    start = [summ[x][0] for x in np.arange(len(summ))]\n",
    "    stop = [summ[x][1] for x in np.arange(len(summ))]\n",
    "    \n",
    "    return Table().with_columns(\"start\", start, \"stop\", stop, \"range\", [i-j for i,j in zip(stop,start)])\n",
    "\n",
    "def tbl_generator(upper,data_comp):\n",
    "        upper = upper\n",
    "        lower = -upper\n",
    "        u = np.mean(data_comp.column(3))\n",
    "        o = np.std(data_comp.column(3))\n",
    "        summary_tbl = data_comp.with_column(\"Greater Binding in Condition 1\", ((data_comp.column(3)-u)/o)>upper)\n",
    "        summary_tbl = summary_tbl.with_column(\"Greater Binding in Condition 2\", ((data_comp.column(3)-u)/o)<lower)\n",
    "\n",
    "        cond_1 = ranges(summary_tbl.where(\"Greater Binding in Condition 1\", are.equal_to(True)).column(0))\n",
    "        cond_2 = ranges(summary_tbl.where(\"Greater Binding in Condition 2\", are.equal_to(True)).column(0))\n",
    "        return cond_1.where(\"range\", are.above(3)), cond_2.where(\"range\", are.above(3)), summary_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regions(read_data,chrom,start,stop):\n",
    "    data_comp = read_data.with_column(\"Adjusted_Fitted_M\", savgol_filter(MA_normalization(read_data).column(\"Adjusted M\"), 21,1))\n",
    "    data_comp_mv = data_comp\n",
    "    data_comp_old = data_comp\n",
    "    Adjusted_Fitted_M = data_comp.column(3)\n",
    "    data_comp = data_comp.select(0,1,2).with_column(\"Adjusted_Fitted_Normalized_M\", (data_comp.column(3)- np.mean(data_comp.column(3))/(np.std(data_comp.column(3)))))\n",
    "    z_score = 1.75\n",
    "    cond1, cond2, summ_tbl = tbl_generator(z_score,data_comp)\n",
    "    true_difference = MA_normalization(read_data).column(\"Adjusted M\")\n",
    "    fin_tbl = Table().with_columns(\"pos\", summ_tbl.column(0), \"diff\", true_difference)\n",
    "    \n",
    "    cond1_differences = make_array()\n",
    "    for i in np.arange(cond1.num_rows):\n",
    "        x = cond1.column(0).item(i)\n",
    "        y = cond1.column(1).item(i)\n",
    "        differences = fin_tbl.where(\"pos\", are.between(x,y + 1)).column(\"diff\")\n",
    "        under_curve = simps(np.abs(differences))\n",
    "        cond1_differences = np.append(cond1_differences, under_curve)\n",
    "    cond1 = cond1.with_column(\"increased binding (unitless)\", cond1_differences)\n",
    "    \n",
    "    cond2_differences = make_array()\n",
    "    for i in np.arange(cond2.num_rows):\n",
    "        x = cond2.column(0).item(i)\n",
    "        y = cond2.column(1).item(i)\n",
    "        differences = fin_tbl.where(\"pos\", are.between(x,y + 1)).column(\"diff\")\n",
    "        under_curve = simps(np.abs(differences))\n",
    "        cond2_differences = np.append(cond2_differences, under_curve)\n",
    "    cond2 = cond2.with_column(\"increased binding (unitless)\", cond2_differences)\n",
    "    \n",
    "    return cond1.column(0), cond1.column(1), cond1.column(2), cond1.column(3), cond2.column(0), cond2.column(1), cond2.column(2), cond2.column(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depth_data(track_files,track_names,chrom,start,stop,strand,track_type):\n",
    "    def view_region(track_file,strand,region):\n",
    "        return subprocess.Popen((\"samtools\", \"view\",\n",
    "                                 strand_to_flag[use_strand],\n",
    "                                 \"-b\",track_file,\n",
    "                                 region),stderr=subprocess.PIPE,stdout=subprocess.PIPE)\n",
    "    mydepths = pd.DataFrame([0]*(stop-start+1),index=range(start,stop+1),columns=[\"depth\"])\n",
    "    depth_list = pd.DataFrame(0,index=range(start,stop),columns=track_names)\n",
    "    strandinvert = {\"+\":\"-\",\"-\":\"+\"}\n",
    "    strand_to_flag = {\"+\":\"-F 0x10\",\n",
    "        \"-\":\"-f 0x10\"}\n",
    "    for n,track_file in enumerate(track_files):\n",
    "        use_strand=strand\n",
    "        region = chrom + \":\" + str(start) + \"-\" + str(stop)\n",
    "        if track_type[n] == \"as\":\n",
    "            use_strand = strandinvert[strand]\n",
    "        # Get sequences from a given region (in binary bam format still)\n",
    "        ps =view_region(track_file,strand_to_flag[use_strand],region)\n",
    "        sout,err = ps.communicate() # get stdout, stderr\n",
    "        ## CHECK TO MAKE SURE THE REFERENCE GENOME CHROMOSOME IS FINE.\n",
    "        if len(err)>0: # is there anytihn in stder?\n",
    "            if b\"specifies an unknown reference name\" in err:\n",
    "                # SWITCH REFERENCE\n",
    "                temp_chrom = chrom.replace(\"chr\",\"\")\n",
    "                region = temp_chrom + \":\" + str(start) + \"-\" + str(stop)\n",
    "                ps =view_region(track_file,strand_to_flag[use_strand],region)\n",
    "                sout,err = ps.communicate()\n",
    "        if len(err)>0:\n",
    "            raise NameError(\"Unknown samtools error. Ran: samtools view %s -b %s %s | samtools depth - \" % (strand_to_flag[use_strand],track_file,region))\n",
    "        # Run samtools depth on the sequences retrieved\n",
    "        ps2 = subprocess.Popen((\"samtools\", \"depth\",\"-\"),stdin=subprocess.PIPE,stdout=subprocess.PIPE)\n",
    "        output,err = ps2.communicate(input=sout)\n",
    "        sample_depths = pd.read_table(BytesIO(output),names=[\"chrom\",\"depth\"],index_col=1)\n",
    "        if len(sample_depths.index)>0:\n",
    "            mydepths.depth = sample_depths.depth\n",
    "            depth_list[track_names[n]] = sample_depths.depth\n",
    "            depth_list = depth_list.fillna(value=0)  \n",
    "    return depth_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 10003/20765 [33:03<21:57,  8.17it/s]  /anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:52: RuntimeWarning: invalid value encountered in greater\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:53: RuntimeWarning: invalid value encountered in less\n",
      " 99%|█████████▉| 20521/20765 [1:14:16<00:46,  5.23it/s]  "
     ]
    }
   ],
   "source": [
    "#cond1,cond2 = regions(read_data,chrom,start,stop)\n",
    "unique_utrs = Table.read_table(\"refseq_3utr.csv\").drop(\"Num\")\n",
    "f1 = \"bams/Loeb_ko_sorted.bam\"\n",
    "f2 = \"bams/Loeb_wt_sorted.bam\"\n",
    "\n",
    "cond1_starts = make_array()\n",
    "cond1_stops = make_array()\n",
    "cond1_ranges = make_array()\n",
    "cond1_binds = make_array()\n",
    "cond1_strands = make_array()\n",
    "cond1_chroms = make_array()\n",
    "cond1_geneIDs = make_array()\n",
    "\n",
    "cond2_starts = make_array()\n",
    "cond2_stops = make_array()\n",
    "cond2_ranges = make_array()\n",
    "cond2_binds = make_array()\n",
    "cond2_strands = make_array()\n",
    "cond2_chroms = make_array()\n",
    "cond2_geneIDs = make_array()\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(np.arange(unique_utrs.num_rows)):\n",
    "    #unique_utrs = unique_utrs.where(\"GeneID\", are.equal_to(\"Actb\"))\n",
    "    chrom = unique_utrs.column(0).item(i)\n",
    "    start = unique_utrs.column(1).item(i)\n",
    "    stop = unique_utrs.column(2).item(i)\n",
    "    strand = unique_utrs.column(4).item(i)\n",
    "    geneid = unique_utrs.column(3).item(i)\n",
    "\n",
    "    region = chrom + \":\" + str(start) + \"-\" + str(stop)\n",
    "    #strand_to_flag = {\"+\":\"-F 0x10\",\"-\":\"-f 0x10\"}\n",
    "    #ps = subprocess.Popen((\"samtools\", \"view\",strand_to_flag[strand],\"-b\",f1,region),stderr=subprocess.PIPE,stdout=subprocess.PIPE)\n",
    "    #sout,err = ps.communicate()\n",
    "    #sample_depths = pd.read_table(BytesIO(output),names=[\"chrom\",\"depth\"],index_col=1)\n",
    "    #ps2 = subprocess.Popen((\"samtools\", \"depth\",\"-\"),stdin=subprocess.PIPE,stdout=subprocess.PIPE)\n",
    "    #output,err = ps2.communicate(input=sout)\n",
    "    #sample_depths = pd.read_table(BytesIO(output),names=[\"chrom\",\"depth\"],index_col=1)\n",
    "\n",
    "    depths = get_depth_data(make_array(f1, f2),make_array(f1, f2),chrom,start,stop,strand,[\"s\", \"s\"])\n",
    "    f1_depths = depths[f1].tolist()\n",
    "    f2_depths = depths[f2].tolist()\n",
    "\n",
    "    reading_data = Table().with_columns(\"Unnamed: 0\",depths.index.tolist(), f1,f1_depths, f2, f2_depths)\n",
    "    if sum(reading_data.column(1)) > 0 and sum(reading_data.column(2)) > 0 and reading_data.num_rows >21:\n",
    "        cond1_start, cond1_stop, cond1_range, cond1_bind, cond2_start, cond2_stop, cond2_range, cond2_bind = regions(reading_data,chrom,start,stop)\n",
    "        \n",
    "        #cond1_start = [int(i) for i in cond1_start]\n",
    "        #cond1_stop = [int(i) for i in cond1_stop]\n",
    "        \n",
    "        cond2_start = [int(i) for i in cond2_start]\n",
    "        cond2_stop = [int(i) for i in cond2_stop]\n",
    "        \n",
    "        cond1_geneID = [geneid for i in np.arange(len(cond1_start))]\n",
    "        cond2_geneID = [geneid for i in np.arange(len(cond2_start))]\n",
    "\n",
    "        cond1_strand = [strand for i in np.arange(len(cond1_start))]\n",
    "        cond2_strand = [strand for i in np.arange(len(cond2_start))]\n",
    "\n",
    "        cond1_chrom = [chrom for i in np.arange(len(cond1_start))]\n",
    "        cond2_chrom = [chrom for i in np.arange(len(cond2_start))]\n",
    "\n",
    "        cond1_starts = np.append(cond1_starts, cond1_start)\n",
    "        cond1_stops = np.append(cond1_stops, cond1_stop)\n",
    "        cond1_binds = np.append(cond1_binds, cond1_bind)\n",
    "        cond1_strands = np.append(cond1_strands, cond1_strand)\n",
    "        cond1_chroms = np.append(cond1_chroms, cond1_chrom)\n",
    "        cond1_geneIDs = np.append(cond1_geneIDs, cond1_geneID)\n",
    "\n",
    "        cond2_starts = np.append(cond2_starts, cond2_start)\n",
    "        cond2_stops = np.append(cond2_stops, cond2_stop)\n",
    "        cond2_binds = np.append(cond2_binds, cond2_bind)\n",
    "        cond2_strands = np.append(cond2_strands, cond2_strand)\n",
    "        cond2_chroms = np.append(cond2_chroms, cond2_chrom)\n",
    "        cond2_geneIDs = np.append(cond2_geneIDs, cond2_geneID)\n",
    "        \n",
    "        \n",
    "cond1_summary = Table().with_columns(\"chrom\",cond1_chroms, \"chromStart\",cond1_starts,  \"chromEnd\",cond1_stops,  \"name\",cond1_geneIDs, \"strand\",cond1_strands, \"differential binding (unitless)\", cond1_binds)\n",
    "cond2_summary = Table().with_columns(\"chrom\",cond2_chroms, \"chromStart\",cond2_starts,  \"chromEnd\",cond2_stops,  \"name\",cond2_geneIDs, \"strand\",cond2_strands, \"differential binding (unitless)\", cond2_binds)\n",
    "cond2_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dclip = Table.read_table(\"dCLIP-1.7-run-1-int/dCLIP_output.txt\")\n",
    "#sites = dclip.where(\"chrom\", are.equal_to(chrom)).where(\"position\", are.between(start, stop + 1)).select(\"chrom\", \"position\", \"state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_cond_1 = dclip.where(\"state\", are.equal_to(2))#.where(\"position\",are.between(limit.item(0), limit.item(1)))\n",
    "d_cond_2 = dclip.where(\"state\", are.equal_to(0))#.where(\"position\",are.between(limit.item(0), limit.item(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "utrs = Table.read_table(\"3'utr.csv\").drop(\"Num\")\n",
    "utrs = utrs.with_column(\"range\", utrs.column(\"Stop\") - (utrs.column(\"Start\")-1))#.group(make_array(0,1,2,3,4), max)\n",
    "unique_names = utrs.group(\"GeneID\").column(0)\n",
    "\n",
    "chroms = make_array()\n",
    "starts = make_array()\n",
    "stops = make_array()\n",
    "geneids = make_array()\n",
    "strands = make_array()\n",
    "ranges = make_array()\n",
    "\n",
    "\n",
    "for i in np.arange(len(unique_names)):\n",
    "    utr = utrs.where(\"GeneID\", are.equal_to(unique_names.item(i))).sort(\"range\", descending=True).take(0)\n",
    "    \n",
    "    chroms = np.append(chroms,utr.column(\"Chrom\").item(0))\n",
    "    starts = np.append(starts,utr.column(\"Start\").item(0))\n",
    "    stops = np.append(stops,utr.column(\"Stop\").item(0))\n",
    "    geneids = np.append(geneids,utr.column(\"GeneID\").item(0))\n",
    "    strands = np.append(strands,utr.column(\"Strand\").item(0))\n",
    "    ranges = np.append(ranges,utr.column(\"range\").item(0))\n",
    "unique_utrs = Table().with_columns(\"Chrom\", chroms, \"Start\", starts, \"Stop\", stops, \"GeneID\", geneids, \"Strand\",strands, \"Range\", ranges)\n",
    "unique_utrs = Table().with_columns(\"Chrom\", unique_utrs.column(\"Chrom\"), \"Start\", [int(i) for i in unique_utrs.column(\"Start\")], \"Stop\", [int(i) for i in unique_utrs.column(\"Stop\")], \"GeneID\",unique_utrs.column(\"GeneID\"), \"Num\",[int(i) for i in np.zeros(unique_utrs.num_rows)], \"Strand\", unique_utrs.column(\"Strand\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
